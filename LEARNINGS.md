# LEARNINGS.md - Slab.AI Full-Stack Deployment
ğŸ“š Learning Pathways
1. Kubernetes Fundamentals
 Core Concepts: Pods, Deployments, Services
Bash

kubectl explain pods.spec  # Discover all pod options
ğŸ” Unexpected Kubernetes Learnings
Q: Why does kubectl get pods show "0/1" when CPU usage is low?
A: Itâ€™s often filesystem issues...

-> Debugging Flowchart:
graph TD
A[Pod Not Running] --> B{Logs?}
B -->|Yes| C[Fix Application]
B -->|No| D[Check Describe]
D --> E[Resources/Probes]

-> Helm Deep Dive
Chart Anatomy:
helm/slab-ai/
â”œâ”€â”€ Chart.yaml # Metadata
â”œâ”€â”€ values.yaml # Configurations
â””â”€â”€ templates/ # K8s manifests
â”œâ”€â”€ deployment.yaml # Pod specs
â””â”€â”€ service.yaml # Networking

Template Functions:

Example: Conditional resources
resources:
{{- if .Values.production }}
limits: { cpu: "1", memory: "1Gi" }
{{- else }}
limits: { cpu: "500m", memory: "256Mi" }
{{- end }}

ğŸ—ï¸ Project-Specific Insights
Key Challenges & Solutions
Problem | Solution | Command
MongoDB Alpine Incompatibility| Used bitnami/mongodb | Helm chart helm install mongodb bitnami/mongodb
CrashLoopBackOff | Added initialDelaySeconds: 30 | kubectl edit deploy/slab-ai
Port Conflicts | Switched to NodePort | kubectl patch svc slab-ai -p '{"spec":{"type":"NodePort"}}'

ğŸ§  Concept Bank
Terms to Master
Liveness Probe: Kubernetes' health check
livenessProbe:
httpGet:
path: /health
port: 3000
initialDelaySeconds: 30

Terraform State: Tracks real-world vs. config
terraform state list # View managed resources

Likely Questions
"How did you debug CrashLoopBackOff?"

Answer Structure:
Checked logs (kubectl logs --previous)
Verified resources (kubectl describe pod)
Adjusted probes (added initialDelaySeconds)
"Why Helm over plain YAML?"

Talking Points:
Template reuse ({{ .Values.image.tag }})
Versioned releases (helm history slab-ai)

ğŸ“… Progress Tracker
2025-09-25
Achieved:
Fixed MongoDB connection issues
Documented Helm value overrides
Next Goals:
Add React frontend to Helm
Configure Prometheus monitoring

ğŸ¯ CRITICAL BREAKTHROUGHS - 2025-09-28
The Great MongoDB Connection Battle (48+ Hours Resolved)
Problem: Backend pods in CrashLoopBackOff due to MongoDB connection failures
Root Cause: Mixed configurations and missing MongoDB service

Key Learnings:

Helm Architecture Separation
Bash

# WRONG: Mixed backend + DB in one values.yaml
# RIGHT: Separate deployments
helm install mongodb bitnami/mongodb -n slab-ai -f mongodb-values.yaml
helm install slab-ai-backend ./helm/slab-ai -n slab-ai

# ğŸš€ Backend Deployment Victory - Learnings
ğŸ¯ The Battle Won: September 28, 2025
"Ad astra per aspera" - through difficulties to the stars!

ğŸ† Key Victories
âœ… MongoDB Connection Stabilized
âœ… /api/leads Endpoint Live
âœ… Helm Charts Corrected & Deployed
âœ… Backend Running in CrashLoopBackOff â†’ Healthy
âœ… Frontend Docker Setup Ready for Next Phase
ğŸ’¡ Critical Insights Gained
Always look for the port configuration and mongo connection,
Pods Logs are useful insight to overcome any POD failure chellange,

ğŸ› ï¸ Tools Mastered
Helm Configuration,Kubernetes PODS configuration

## ğŸš€ DEPLOYMENT VICTORIES
### **Frontend-Backend Helm Integration (2025-10-05)**
- **Fixed**: Label mismatches in Helm templates  
- **Solved**: Port conflicts between dev (Vite) and prod (K8s)  
- **Verified**: Full-stack access via:
  ```bash
  # Frontend (Prod)
  kubectl port-forward svc/slab-ai-chart-frontend 8080:80
  # Backend (API)
  kubectl port-forward svc/slab-ai-backend 8082:3000
ğŸ› ï¸ KEY COMMANDS
Scenario	Command
Fix Helm label conflicts	kubectl delete ingress,svc -n slab-ai -l app.kubernetes.io/instance=slab-ai-backend
Debug CrashLoopBackOff	kubectl logs -n slab-ai <pod-name> --previous
Check port occupancy	netstat -ano | findstr 8082 (Windows) / lsof -i :8082 (Linux/Mac)
ğŸ“š CORE INSIGHTS
Helm Best Practices
Label Consistency:

YAML

# templates/frontend-deployment.yaml
selector:
  matchLabels:
    app.kubernetes.io/name: {{ include "slab-ai-chart.name" . }}-frontend
template:
  metadata:
    labels:
      app.kubernetes.io/name: {{ include "slab-ai-chart.name" . }}-frontend
Probes Matter:

YAML

livenessProbe:
  httpGet:
    path: /
    port: 80
  initialDelaySeconds: 15  
  
# Critical for slow-starting containers
ğŸŒ ENVIRONMENT ACCESS
Component	Dev (Local)	Prod (K8s)
Frontend	localhost:5173	localhost:8080
Backend	Proxy to :8082	localhost:8082

ğŸš¨ GOTCHAS & SOLUTIONS
"Port already in use"
â†’ Run kubectl port-forward in separate terminals or background with &

Helm "invalid ownership" errors
â†’ Always clean old releases:

Bash

helm uninstall slab-ai-backend -n slab-ai
kubectl delete svc,deploy -n slab-ai -l app.kubernetes.io/instance=slab-ai-backend
ğŸ¯ NEXT STEPS
Configure Ingress:
Bash

kubectl apply -f helm/slab-ai/templates/ingress.yaml
Set up CI/CD (GitHub Actions example):
YAML

- name: Deploy to K8s
  run: |
    helm upgrade slab-ai ./helm/slab-ai -n slab-ai
